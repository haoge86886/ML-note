#数据标准化

#当几种特征的数字相差量级很大时,不利于w,b的设定
#可以使用特征缩放,使得几种特征都在一定范围内(比如[0,1]),使得梯度下降能处于一种适当的速度

#均值归一化
#比如特征x1的平均值是μ1,极差是m,让
#                   x1 = (x11-μ1,x12-μ1,.......,x1n-μ1)/m
#得到的数据范围在[0,1]之间

#Z分数标准化
#数据的均值为μ,标准差为σ
#                  x1 = (x11-μ1,x12-μ1,.......,x1n-μ1)/σ



#学习率设置

#梯度下降收敛
#随着训练次数不断增加,loss应该是收敛的
#用一个横轴是训练次数,纵轴是loss的函数,可以清晰地发现梯度下降是否正常运行
#如果不是一个单调递减并向横轴收敛的函数,可能学习率设置不正确

#学习率初始选择
#可以从较小的学习率开始逐渐加大,判断梯度下降是否正常运行
#较小的学习率会导致函数过于平缓,过大的可能会不是单调函数或是单点递增


#特征工程

#一个数据可能有很多特征,如何正确选择有利于问题的解决
#同时也可以组合特征为新的特征,可以得到更好的模型