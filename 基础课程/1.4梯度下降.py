"""""""""
沿着当前函数的负梯度方向,不断向下,知道最小值
目标是将成本函数J(w,b)下降到最小

数学过程
可以将初始值设置为w=0,b=0,从起始点出发,研负梯度方向前进
temp_w = w ﹣α * ∂J(w,b)/∂w
temp_b = b ﹣α * ∂J(w,b)/∂b
w = temp_w                                       确保同步更新
b = temp_b

参数
∂J(w,b)/∂w                                       导数项

α:学习率,通常在0~1,决定了每次更新前进的步长大小,不能太大也不能太小
 1.固定学习率:每次走相同的步长
 2.逐渐衰减学习率:在接近最小值时步长减小,会更精确
 3.自适应学习率:不断调整步长
 4.周期性变化学习率:

局部最小与全剧最小
对于多个极值点的函数,找到了最小值不一定是全剧最小
但平方成本函数是个凸函数,不用考虑这个问题

用于线性回归的梯度下降,结合平方成本函数
w - α * 1/m ∑ (w * xi + b - yi) * xi
b - α * 1/m ∑ (w * xi + b - yi)


分类:
    批次梯度下降 : 每次对所有特征的参数进行梯度下降
    随机梯度下降 : 每次只对一个特征梯度下降,能跳出局部最小
    小批量梯度下降 : 每次对一小批特征参数梯度下降
    

"""""""""



